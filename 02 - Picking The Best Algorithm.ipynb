{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from helpers.rmse import rmse, rmse_scorer\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit, train_test_split, RandomizedSearchCV\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix seed\n",
    "SEED = 123\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocess train and test data\n",
    "train = pd.read_csv('data/train_abt.csv')\n",
    "test = pd.read_csv('data/test_abt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>log_trip_duration</th>\n",
       "      <th>haversine_distance</th>\n",
       "      <th>manhattan_distance</th>\n",
       "      <th>euclidean_distance</th>\n",
       "      <th>vendor_id_1</th>\n",
       "      <th>vendor_id_2</th>\n",
       "      <th>...</th>\n",
       "      <th>dropoff_cluster_90</th>\n",
       "      <th>dropoff_cluster_91</th>\n",
       "      <th>dropoff_cluster_92</th>\n",
       "      <th>dropoff_cluster_93</th>\n",
       "      <th>dropoff_cluster_94</th>\n",
       "      <th>dropoff_cluster_95</th>\n",
       "      <th>dropoff_cluster_96</th>\n",
       "      <th>dropoff_cluster_97</th>\n",
       "      <th>dropoff_cluster_98</th>\n",
       "      <th>dropoff_cluster_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-73.982155</td>\n",
       "      <td>40.767937</td>\n",
       "      <td>-73.964630</td>\n",
       "      <td>40.765602</td>\n",
       "      <td>6.122493</td>\n",
       "      <td>1.498521</td>\n",
       "      <td>0.019859</td>\n",
       "      <td>0.017680</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-73.980415</td>\n",
       "      <td>40.738564</td>\n",
       "      <td>-73.999481</td>\n",
       "      <td>40.731152</td>\n",
       "      <td>6.498282</td>\n",
       "      <td>1.805507</td>\n",
       "      <td>0.026478</td>\n",
       "      <td>0.020456</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-73.979027</td>\n",
       "      <td>40.763939</td>\n",
       "      <td>-74.005333</td>\n",
       "      <td>40.710087</td>\n",
       "      <td>7.661527</td>\n",
       "      <td>6.385098</td>\n",
       "      <td>0.080158</td>\n",
       "      <td>0.059934</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-74.010040</td>\n",
       "      <td>40.719971</td>\n",
       "      <td>-74.012268</td>\n",
       "      <td>40.706718</td>\n",
       "      <td>6.063785</td>\n",
       "      <td>1.485498</td>\n",
       "      <td>0.015480</td>\n",
       "      <td>0.013438</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-73.973053</td>\n",
       "      <td>40.793209</td>\n",
       "      <td>-73.972923</td>\n",
       "      <td>40.782520</td>\n",
       "      <td>6.077642</td>\n",
       "      <td>1.188588</td>\n",
       "      <td>0.010818</td>\n",
       "      <td>0.010690</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 274 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pickup_longitude  pickup_latitude  dropoff_longitude  dropoff_latitude  \\\n",
       "0        -73.982155        40.767937         -73.964630         40.765602   \n",
       "1        -73.980415        40.738564         -73.999481         40.731152   \n",
       "2        -73.979027        40.763939         -74.005333         40.710087   \n",
       "3        -74.010040        40.719971         -74.012268         40.706718   \n",
       "4        -73.973053        40.793209         -73.972923         40.782520   \n",
       "\n",
       "   log_trip_duration  haversine_distance  manhattan_distance  \\\n",
       "0           6.122493            1.498521            0.019859   \n",
       "1           6.498282            1.805507            0.026478   \n",
       "2           7.661527            6.385098            0.080158   \n",
       "3           6.063785            1.485498            0.015480   \n",
       "4           6.077642            1.188588            0.010818   \n",
       "\n",
       "   euclidean_distance  vendor_id_1  vendor_id_2         ...          \\\n",
       "0            0.017680            0            1         ...           \n",
       "1            0.020456            1            0         ...           \n",
       "2            0.059934            0            1         ...           \n",
       "3            0.013438            0            1         ...           \n",
       "4            0.010690            0            1         ...           \n",
       "\n",
       "   dropoff_cluster_90  dropoff_cluster_91  dropoff_cluster_92  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   dropoff_cluster_93  dropoff_cluster_94  dropoff_cluster_95  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   dropoff_cluster_96  dropoff_cluster_97  dropoff_cluster_98  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   1   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   dropoff_cluster_99  \n",
       "0                   0  \n",
       "1                   0  \n",
       "2                   0  \n",
       "3                   0  \n",
       "4                   0  \n",
       "\n",
       "[5 rows x 274 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify and check train data\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>haversine_distance</th>\n",
       "      <th>manhattan_distance</th>\n",
       "      <th>euclidean_distance</th>\n",
       "      <th>vendor_id_1</th>\n",
       "      <th>vendor_id_2</th>\n",
       "      <th>passenger_count_0</th>\n",
       "      <th>...</th>\n",
       "      <th>dropoff_cluster_90</th>\n",
       "      <th>dropoff_cluster_91</th>\n",
       "      <th>dropoff_cluster_92</th>\n",
       "      <th>dropoff_cluster_93</th>\n",
       "      <th>dropoff_cluster_94</th>\n",
       "      <th>dropoff_cluster_95</th>\n",
       "      <th>dropoff_cluster_96</th>\n",
       "      <th>dropoff_cluster_97</th>\n",
       "      <th>dropoff_cluster_98</th>\n",
       "      <th>dropoff_cluster_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-73.988129</td>\n",
       "      <td>40.732029</td>\n",
       "      <td>-73.990173</td>\n",
       "      <td>40.756680</td>\n",
       "      <td>2.746426</td>\n",
       "      <td>0.026695</td>\n",
       "      <td>0.024735</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-73.964203</td>\n",
       "      <td>40.679993</td>\n",
       "      <td>-73.959808</td>\n",
       "      <td>40.655403</td>\n",
       "      <td>2.759239</td>\n",
       "      <td>0.028984</td>\n",
       "      <td>0.024979</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-73.997437</td>\n",
       "      <td>40.737583</td>\n",
       "      <td>-73.986160</td>\n",
       "      <td>40.729523</td>\n",
       "      <td>1.306155</td>\n",
       "      <td>0.019337</td>\n",
       "      <td>0.013861</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-73.956070</td>\n",
       "      <td>40.771900</td>\n",
       "      <td>-73.986427</td>\n",
       "      <td>40.730469</td>\n",
       "      <td>5.269088</td>\n",
       "      <td>0.071789</td>\n",
       "      <td>0.051363</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-73.970215</td>\n",
       "      <td>40.761475</td>\n",
       "      <td>-73.961510</td>\n",
       "      <td>40.755890</td>\n",
       "      <td>0.960842</td>\n",
       "      <td>0.014290</td>\n",
       "      <td>0.010343</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 273 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pickup_longitude  pickup_latitude  dropoff_longitude  dropoff_latitude  \\\n",
       "0        -73.988129        40.732029         -73.990173         40.756680   \n",
       "1        -73.964203        40.679993         -73.959808         40.655403   \n",
       "2        -73.997437        40.737583         -73.986160         40.729523   \n",
       "3        -73.956070        40.771900         -73.986427         40.730469   \n",
       "4        -73.970215        40.761475         -73.961510         40.755890   \n",
       "\n",
       "   haversine_distance  manhattan_distance  euclidean_distance  vendor_id_1  \\\n",
       "0            2.746426            0.026695            0.024735            1   \n",
       "1            2.759239            0.028984            0.024979            1   \n",
       "2            1.306155            0.019337            0.013861            1   \n",
       "3            5.269088            0.071789            0.051363            0   \n",
       "4            0.960842            0.014290            0.010343            1   \n",
       "\n",
       "   vendor_id_2  passenger_count_0         ...          dropoff_cluster_90  \\\n",
       "0            0                  0         ...                           0   \n",
       "1            0                  0         ...                           0   \n",
       "2            0                  0         ...                           0   \n",
       "3            1                  0         ...                           0   \n",
       "4            0                  0         ...                           0   \n",
       "\n",
       "   dropoff_cluster_91  dropoff_cluster_92  dropoff_cluster_93  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   1                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   dropoff_cluster_94  dropoff_cluster_95  dropoff_cluster_96  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   dropoff_cluster_97  dropoff_cluster_98  dropoff_cluster_99  \n",
       "0                   0                   0                   0  \n",
       "1                   0                   0                   0  \n",
       "2                   0                   0                   0  \n",
       "3                   0                   0                   0  \n",
       "4                   0                   0                   0  \n",
       "\n",
       "[5 rows x 273 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify and check train data\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop('log_trip_duration', axis=1).values\n",
    "y = train.log_trip_duration.values\n",
    "\n",
    "X_test = test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Benchmark\n",
    "Now we are ready to train our models. However, we have to perform and create our milestone to be as a goal to beat first, Benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training set for benchmark purpose only\n",
    "X_train_benchmark, X_valid_benchmark, y_train_benchmark, y_valid_benchmark = train_test_split(X, y, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initiate Linear Regression Instance and train model\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train_benchmark, y_train_benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6029172150450034"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Local validation score \n",
    "valid_pred = reg.predict(X_valid_benchmark)\n",
    "# rmse in this case is the same as rmsle because we did log transformation for trip duration already\n",
    "rmse(y_valid_benchmark, valid_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set score: submit to kaggle leaderboard\n",
    "test_pred = reg.predict(X_test)\n",
    "\n",
    "sub = pd.DataFrame()    \n",
    "sub['id'] = pd.read_csv('data/test.csv').id\n",
    "sub['trip_duration'] = np.expm1(test_pred)\n",
    "\n",
    "sub.to_csv('sub/benchmark_sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSLE benchmark on validation set is 0.6029172150450034 <br>\n",
    "RMSLE benchmark on public leaderboard (30% of test set) is 0.60910 <br>\n",
    "RMSLE benchmark on private leaderboard (70% of test set) is 0.72923"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all unused variables \n",
    "del X_train_benchmark, X_valid_benchmark, y_train_benchmark, y_valid_benchmark, valid_pred, test_pred, sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick the best model\n",
    "After setting up the benchmark, the next process is to train, evaluate and pick the best performing model in this data set. Our candidates are Ridge Regression, Random Forest, and Gradient Boosing tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Instances and store in dictionary so that it is easy to loop later\n",
    "models = {\n",
    "    'xgb': xgb.XGBRegressor(tree_method='hist', n_jobs=-1, random_state=SEED),\n",
    "    'ridge': Ridge(random_state=SEED),\n",
    "    'rf': RandomForestRegressor(n_jobs=-1, random_state=SEED)\n",
    "}\n",
    "\n",
    "ridge_hyperparameters = {\n",
    "    'alpha': [0.01, 0.1, 0.5, 1, 5]\n",
    "}\n",
    "\n",
    "rf_hyperparameters = {\n",
    "    'n_estimators' : [200, 500, 1000],\n",
    "    'max_features': ['auto'],\n",
    "    'max_depth': [5, 7, 10]\n",
    "}\n",
    "\n",
    "xgb_hyperparameters = {\n",
    "    'n_estimators': [500, 1000, 2000],\n",
    "    'learning_rate' : [0.01, 0.1],\n",
    "    'max_depth': [5, 7, 9],\n",
    "    'subsample': [0.7, 0.8, 0.9],\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9]\n",
    "}\n",
    "\n",
    "# Store hyperparameters\n",
    "hyperparameters = {\n",
    "    'ridge' : ridge_hyperparameters,\n",
    "    'rf' : rf_hyperparameters,\n",
    "    'xgb' : xgb_hyperparameters\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 3 candidates, totalling 3 fits\n",
      "[CV] subsample=0.8, n_estimators=1000, max_depth=5, learning_rate=0.1, colsample_bytree=0.9 \n",
      "[13:04:55] Tree method is selected to be 'hist', which uses a single updater grow_fast_histmaker.\n",
      "[CV]  subsample=0.8, n_estimators=1000, max_depth=5, learning_rate=0.1, colsample_bytree=0.9, score=-0.40830638788893603, total= 4.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  5.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] subsample=0.7, n_estimators=500, max_depth=7, learning_rate=0.1, colsample_bytree=0.9 \n",
      "[13:10:11] Tree method is selected to be 'hist', which uses a single updater grow_fast_histmaker.\n",
      "[CV]  subsample=0.7, n_estimators=500, max_depth=7, learning_rate=0.1, colsample_bytree=0.9, score=-0.4067131487628946, total= 3.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  8.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] subsample=0.8, n_estimators=500, max_depth=9, learning_rate=0.01, colsample_bytree=0.9 \n",
      "[13:13:18] Tree method is selected to be 'hist', which uses a single updater grow_fast_histmaker.\n",
      "[CV]  subsample=0.8, n_estimators=500, max_depth=9, learning_rate=0.01, colsample_bytree=0.9, score=-0.4347221765148964, total= 5.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 13.7min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 13.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:18:37] Tree method is selected to be 'hist', which uses a single updater grow_fast_histmaker.\n",
      "xgb has done\n",
      "Fitting 1 folds for each of 3 candidates, totalling 3 fits\n",
      "[CV] alpha=5 .........................................................\n",
      "[CV] ............... alpha=5, score=-0.6022829963174543, total=  25.6s\n",
      "[CV] alpha=0.5 .......................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   26.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............. alpha=0.5, score=-0.6028501922562434, total=  10.8s\n",
      "[CV] alpha=0.1 .......................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   38.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............. alpha=0.1, score=-0.6029038342545151, total=  10.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   49.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   49.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ridge has done\n",
      "Fitting 1 folds for each of 3 candidates, totalling 3 fits\n",
      "[CV] n_estimators=200, max_features=auto, max_depth=7 ................\n",
      "[CV]  n_estimators=200, max_features=auto, max_depth=7, score=-0.47716018767823215, total=29.4min\n",
      "[CV] n_estimators=500, max_features=auto, max_depth=10 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 29.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=500, max_features=auto, max_depth=10, score=-0.4622597021424335, total=98.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 128.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] n_estimators=500, max_features=auto, max_depth=7 ................\n",
      "[CV]  n_estimators=500, max_features=auto, max_depth=7, score=-0.477107780732511, total=73.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 202.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 202.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf has done\n"
     ]
    }
   ],
   "source": [
    "# Train each model with 3 random combinations of hyperparameters\n",
    "fitted_models = {}\n",
    "shuffle = ShuffleSplit(n_splits=1, test_size=0.2, random_state=SEED)\n",
    "\n",
    "for name, reg in models.items():\n",
    "    model = RandomizedSearchCV(reg , hyperparameters[name], \n",
    "                               n_iter=3,\n",
    "                               cv=shuffle, \n",
    "                               scoring=rmse_scorer,\n",
    "                               verbose=5,\n",
    "                               n_jobs=1)\n",
    "    \n",
    "    model.fit(X , y)\n",
    "    # Store model in dictionary\n",
    "    fitted_models[name] = model\n",
    "    \n",
    "    print(name, 'has done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb [-0.40830639 -0.40671315 -0.43472218]\n",
      "ridge [-0.602283   -0.60285019 -0.60290383]\n",
      "rf [-0.47716019 -0.4622597  -0.47710778]\n"
     ]
    }
   ],
   "source": [
    "# Display rmsle on all validation sets\n",
    "for name , model in fitted_models.items():\n",
    "    print(name , model.cv_results_['mean_test_score'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb -0.4067131487628946\n",
      "ridge -0.6022829963174543\n",
      "rf -0.46225970214243345\n"
     ]
    }
   ],
   "source": [
    "# Print out the best score for each algorithm\n",
    "for name , model in fitted_models.items():\n",
    "    print(name , model.best_score_ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the score above, Ridge regression, regularized linear regression, has the same performance to our benchmark; it is not a good model to beat benchmark in this situation. However, with tree models, they both have performed better than benchmark model but Gradient boosting tree is doing a lot better comparing to Random Forrest. Thus, we are going to use gradient boosting tree (XGBoost) for the rest of the process. The next part is to find the optimal hyperparameters for xgboost which can be found on searching hyperparameters notebook in the same folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save test prediciton to evaluate on the kaggle leaderboard\n",
    "for name , model in fitted_models.items():\n",
    "    pred = model.predict(X_test)\n",
    "    \n",
    "    sub = pd.DataFrame()    \n",
    "    sub['id'] = pd.read_csv('data/test.csv').id\n",
    "    sub['trip_duration'] = np.expm1(pred)\n",
    "    sub.to_csv('sub/' + name + '_sub.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
